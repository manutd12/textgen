torchrun --nproc_per_node 8 finetune_searchad.py \
  --num_epochs 5 \
  --batch_size 8 \
  --model_type chatglm \
  --max_seq_length 128 \
  --max_length 512 \
  --model_name /apdcephfs/private_curvasong/output/ad_glm_rrhf_ddp/merge_lora \
  --do_train \
  --output_dir /apdcephfs/private_curvasong/output/glm_rrhf_sft \
  --save_total_limit 10 \
  --save_strategy epoch \